{
    "componentChunkName": "component---src-templates-tutorial-tsx",
    "path": "/machine-learning/using-machine-learning-to-detect-fake-news",
    "result": {"data":{"post":{"slug":"/machine-learning/using-machine-learning-to-detect-fake-news","title":"Using Machine Learning to detect fake news!","description":"Develop a machine learning model to identify when an article might be fake news.","excerpt":"Data has become the center of today’s’ businesses. In this modern world, 1.7 megaBytes data is generated per second. Many technologies have…","body":"var _excluded = [\"components\"];\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n/* @jsxRuntime classic */\n/* @jsx mdx */\n\nvar _frontmatter = {\n  \"title\": \"Using Machine Learning to detect fake news!\",\n  \"subtitle\": \"\",\n  \"date\": \"2020-08-02T00:00:00.000Z\",\n  \"lastUpdated\": \"2021-08-07T00:00:00.000Z\",\n  \"description\": \"Develop a machine learning model to identify when an article might be fake news.\",\n  \"type\": \"tutorial\",\n  \"category\": \"Machine Learning\",\n  \"image\": \"/og-images/theme-ui-plugin.png?v=1\",\n  \"published\": true\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n    props = _objectWithoutProperties(_ref, _excluded);\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"Data has become the center of today\\u2019s\\u2019 businesses. In this modern world, 1.7 megaBytes data is generated per second. Many technologies have evolved to use this massive data for a better world. Machine learning is one of them and today we plan to use it to detect fake news.\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1024px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/53106169f89ae7a2596d26f9b367846b/9a593/fake.jpg\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"100%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGAABAAMBAAAAAAAAAAAAAAAAAAIDBAH/xAAXAQADAQAAAAAAAAAAAAAAAAAAAgMB/9oADAMBAAIQAxAAAAHZ2deNhXrLurJkg0f/xAAcEAACAgIDAAAAAAAAAAAAAAAAAQIDBBESISL/2gAIAQEAAQUC22euLyIsmtPbKoVyhaJdM//EABcRAAMBAAAAAAAAAAAAAAAAAAABEBL/2gAIAQMBAT8BNKM//8QAGREAAgMBAAAAAAAAAAAAAAAAAAECITEy/9oACAECAQE/AROhckcP/8QAHhAAAQQBBQAAAAAAAAAAAAAAAAEREiECEBMxYqH/2gAIAQEABj8CyOsbKXw4IrY+3EQfT//EABwQAAIDAAMBAAAAAAAAAAAAAAERACExQVFhcf/aAAgBAQABPyGtKCNR9CF8whuIJ7euYRNgK0Nj4EnjMIgX5gjRc1P/2gAMAwEAAgADAAAAEPPvff/EABkRAQEAAwEAAAAAAAAAAAAAAAEAESExcf/aAAgBAwEBPxAy7knDHXy6v//EABkRAAIDAQAAAAAAAAAAAAAAAAABESExcf/aAAgBAgEBPxCJSaK1GHTM/8QAHhABAAICAwADAAAAAAAAAAAAAQARIUExUXFhofH/2gAIAQEAAT8QxQFZBzj8jltULcrNMsjBh0HYfEpKkRQ7cfqDhGkB333wS1WKyh7EETe/kCMN3PizoAvqf//Z')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"fake news\",\n    \"title\": \"fake news\",\n    \"src\": \"/static/53106169f89ae7a2596d26f9b367846b/87945/fake.jpg\",\n    \"srcSet\": [\"/static/53106169f89ae7a2596d26f9b367846b/b95e4/fake.jpg 256w\", \"/static/53106169f89ae7a2596d26f9b367846b/1779b/fake.jpg 512w\", \"/static/53106169f89ae7a2596d26f9b367846b/87945/fake.jpg 1024w\", \"/static/53106169f89ae7a2596d26f9b367846b/6afe2/fake.jpg 1536w\", \"/static/53106169f89ae7a2596d26f9b367846b/7a411/fake.jpg 2048w\", \"/static/53106169f89ae7a2596d26f9b367846b/9a593/fake.jpg 3000w\"],\n    \"sizes\": \"(max-width: 1024px) 100vw, 1024px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \")), mdx(\"h2\", {\n    \"id\": \"what-exactly-is-fake-news\"\n  }, \"What exactly is fake news?\"), mdx(\"p\", null, \"Fake news is pieces of misinformation that are often incorporated to mislead people. Fake news is easy to spread as it carries no verification evidence. This is often done to further or impose certain ideas and is often achieved with political agendas.\"), mdx(\"h2\", {\n    \"id\": \"how-do-we-plan-to-solve-it\"\n  }, \"How do we plan to solve it?\"), mdx(\"p\", null, \"This project is broken down into 5 steps, namely:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Loading the data\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Format the data\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Tokenize the data\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Build our model\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Train multiple models\")), mdx(\"p\", null, \"Let us get started on detecting the fake news!\"), mdx(\"h3\", {\n    \"id\": \"loading-the-data\"\n  }, \"Loading the Data\"), mdx(\"p\", null, \"I have used the \\u201CFake or Real News Dataset\\u201D from Kaggle : \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset\"\n  }, \"https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset\"), \" .\\nThe dataset comprises 2 csv files, namely fake and true. Both the files are available on kaggle for download.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-py\"\n  }, \"df_fake = pd.read_csv('Fake.csv')\\ndf_true = pd.read_csv('True.csv')\\n\")), mdx(\"p\", null, \"The initial step would be to merge both the files to have one single file for both train and testing. However, before merging we need to add labels to it. We consider 1 for True and 0 for False. We introduce a new column called \\u2018class\\u2019.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-py\"\n  }, \"df_fake['class'] = 0\\ndf_true['class'] = 1\\n\")), mdx(\"p\", null, \"After doing that, we simply merge both the files.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-py\"\n  }, \"df_merge = pd.concat([df_fake, df_true], axis =0 )\\n\")), mdx(\"h3\", {\n    \"id\": \"format-the-data\"\n  }, \"Format the data\"), mdx(\"p\", null, \"Data preprocessing is a vital step to build a good model. Let us see the columns we have :\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-py\"\n  }, \"df_merge.columns\\n\")), mdx(\"p\", null, \"For simplicity, we remove the columns \\u201Ctitle\\u201D, \\u201Csubject\\u201D,\\u201Cdate\\u201D and retain the text and class column for further processing.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-py\"\n  }, \"df = df_merge.drop([\\\"title\\\", \\\"subject\\\",\\\"date\\\"], axis = 1)\\n\")), mdx(\"p\", null, \"Next we check for any null values,\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-py\"\n  }, \"df.isnull().sum()\\n\")), mdx(\"p\", null, \"Great, we have no null values. Now let us replace the index column and have a cleaner dataset.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-py\"\n  }, \"df.reset_index(inplace = True)\\ndf.drop([\\\"index\\\"], axis = 1, inplace = True)\\n\")), mdx(\"p\", null, \"I have defined a function wordopt below that performs basic regex operations on the text columns and modifies text on the following parameters:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Removes URLs and website links.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Removes unwanted spacings.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Replaces punctuations with a single space.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Removes line spacings.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Converts words in its lowercase.\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-py\"\n  }, \"def wordopt(text):\\n    text = text.lower()\\n    text = re.sub('\\\\[.*?\\\\]', '', text)\\n    text = re.sub(\\\"\\\\\\\\W\\\",\\\" \\\",text)\\n    text = re.sub('https?://\\\\S+|www\\\\.\\\\S+', '', text)\\n    text = re.sub('<.*?>+', '', text)\\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\\n    text = re.sub('\\\\\\\\n', '', text)\\n    text = re.sub('\\\\w*\\\\d\\\\w*', '', text)\\n    return text\\n\")), mdx(\"p\", null, \"This function is then applied to our text column,\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-py\"\n  }, \"df[\\\"text\\\"] = df[\\\"text\\\"].apply(wordopt)\\n\")), mdx(\"p\", null, \"Before performing tokenization, we have one final step to do. Split the dataset into test and train. We consider having a 70 - 30 split.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-py\"\n  }, \"x = df['text']\\ny = df['class']\\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\\n\")), mdx(\"h3\", {\n    \"id\": \"tokenize-the-data\"\n  }, \"Tokenize the data\"), mdx(\"p\", null, \"We use TF IDF to convert the text input into vectors. The explanation of TF IDF is out of scope for this blog, however, you may refer to get a deeper understanding. We use sklearn library to perform the steps.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-py\"\n  }, \"from sklearn.feature_extraction.text import TfidfVectorizer\\n\\nvectorization = TfidfVectorizer()\\nxv_train = vectorization.fit_transform(x_train)\\nxv_test = vectorization.transform(x_test)\\n\")), mdx(\"p\", null, \"Now, that we have the tokenized data, let\\u2019s build our first model.\"), mdx(\"h3\", {\n    \"id\": \"building-the-model\"\n  }, \"Building the Model\"), mdx(\"p\", null, \"We plan to build 4 different models and then compare them to choose the best one.\"), mdx(\"h4\", {\n    \"id\": \"logistic-regression\"\n  }, \"Logistic Regression\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-py\"\n  }, \"from sklearn.linear_model import LogisticRegression\\n\\nLR = LogisticRegression()\\nLR.fit(xv_train,y_train)\\n\")), mdx(\"p\", null, \"Currently, we use the predefined model parameters.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-py\"\n  }, \"pred_lr=LR.predict(xv_test)\\n\")), mdx(\"p\", null, \"Further on, we now try to find the score.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-py\"\n  }, \"LR.score(xv_test, y_test)\\n\")), mdx(\"p\", null, \"Lastly, let us take a look at the classification report:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-py\"\n  }, \"print(classification_report(y_test,pred_lr))\\n\")), mdx(\"h4\", {\n    \"id\": \"decision-tree\"\n  }, \"Decision Tree\"), mdx(\"p\", null, \"Performing similar modeling steps as above,\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-py\"\n  }, \"from sklearn.tree import DecisionTreeClassifier\\n\\nDT = DecisionTreeClassifier()\\nDT.fit(xv_train, y_train)\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-py\"\n  }, \"pred_dt = DT.predict(xv_test)\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-py\"\n  }, \"DT.score(xv_test, y_test)\\n\")), mdx(\"p\", null, \"We already see a slight improvement over Random Forest. The classification report of Decision tree is shown below:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-py\"\n  }, \"print(classification_report(y_test, pred_dt))\\n\")), mdx(\"h4\", {\n    \"id\": \"gradient-boosting-classifier\"\n  }, \"Gradient boosting classifier\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-py\"\n  }, \"from sklearn.ensemble import GradientBoostingClassifier\\n\\nGBC = GradientBoostingClassifier(random_state=0)\\nGBC.fit(xv_train, y_train)\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-py\"\n  }, \"pred_gbc = GBC.predict(xv_test)\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-py\"\n  }, \"GBC.score(xv_test, y_test)\\n\")), mdx(\"p\", null, \"The score of the gradient boosting classifier is similar to that of the decision tree. Let us look at the classification report to find more:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-py\"\n  }, \"print(classification_report(y_test, pred_gbc))\\n\")), mdx(\"h4\", {\n    \"id\": \"random-forest\"\n  }, \"Random Forest\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-py\"\n  }, \"from sklearn.ensemble import RandomForestClassifier\\n\\nRFC = RandomForestClassifier(random_state=0)\\nRFC.fit(xv_train, y_train)\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-py\"\n  }, \"pred_rfc = RFC.predict(xv_test)\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-py\"\n  }, \"RFC.score(xv_test, y_test)\\n\")), mdx(\"p\", null, \"As noticed, Random forest outperforms all the above models. Checking the classification report below:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-py\"\n  }, \"print(classification_report(y_test, pred_rfc))\\n\")), mdx(\"p\", null, \"Now that we have trained different models, we can use them for evaluation on unseen or new data. You can find the complete code on the notebook here: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://bit.ly/3w9qljr\"\n  }, \"https://bit.ly/3w9qljr\")), mdx(\"p\", null, \"Please note the models can be further improved by changing their hyperparameters. You can also experiment with considering both the titles and text for detecting fake news. The possibilities are endless.\"), mdx(\"p\", null, \"I hope this notebook was of help. Do let me know if you have any questions or used different methods to train your model.\"));\n}\n;\nMDXContent.isMDXComponent = true;","seoLastUpdated":"2021-08-07T00:00:00.000Z","lastUpdated":"Aug 07, 2021","seoDate":"2020-08-02T00:00:00.000Z","yearDate":"2020","date":"Aug 02, 2020","subtitle":null,"timeToRead":2,"image":"/og-images/theme-ui-plugin.png?v=1","category":{"name":"Machine Learning","slug":"/machine-learning"},"parent":{"parent":{"relativePath":"2020-08-02-using-NLP-to-detect-Fake-news/index.mdx"}},"tableOfContents":{"items":[{"url":"#what-exactly-is-fake-news","title":"What exactly is fake news?"},{"url":"#how-do-we-plan-to-solve-it","title":"How do we plan to solve it?","items":[{"url":"#loading-the-data","title":"Loading the Data"},{"url":"#format-the-data","title":"Format the data"},{"url":"#tokenize-the-data","title":"Tokenize the data"},{"url":"#building-the-model","title":"Building the Model","items":[{"url":"#logistic-regression","title":"Logistic Regression"},{"url":"#decision-tree","title":"Decision Tree"},{"url":"#gradient-boosting-classifier","title":"Gradient boosting classifier"},{"url":"#random-forest","title":"Random Forest"}]}]}]}}},"pageContext":{"slug":"/machine-learning/using-machine-learning-to-detect-fake-news"}},
    "staticQueryHashes": ["2299006781","3050858678","4184542181","712324210"]}